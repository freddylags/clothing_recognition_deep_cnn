{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##  Purpose: Build CNN model in Functional API for compatibility with Grad-CAM + Gradio"
      ],
      "metadata": {
        "id": "YfZMrEi2sQ0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data_preparation"
      ],
      "metadata": {
        "id": "K3TcznuMsb2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiir8sA0sL2z",
        "outputId": "63c84892-11db-4fb7-866f-65b317d2c1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] X_train shape: (60000, 28, 28, 1)\n",
            "[INFO] X_test shape: (10000, 28, 28, 1)\n",
            "[INFO] y_train shape: (60000,)\n",
            "[INFO] y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "# Set a global random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load Fashion MNIST dataset directly from Keras\n",
        "# It returns: (X_train, y_train), (X_test, y_test)\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to range [0, 1] by dividing by 255\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Reshape input data to add a channel dimension (since images are grayscale)\n",
        "# Shape becomes (num_samples, 28, 28, 1) for CNN compatibility\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# Print dataset shapes for confirmation\n",
        "print(f\"[INFO] X_train shape: {X_train.shape}\")\n",
        "print(f\"[INFO] X_test shape: {X_test.shape}\")\n",
        "print(f\"[INFO] y_train shape: {y_train.shape}\")\n",
        "print(f\"[INFO] y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# defining the model that will be compatibel with gradio"
      ],
      "metadata": {
        "id": "NduiY5ubs7WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Define input shape explicitly\n",
        "# -----------------------------\n",
        "# This ensures the model has a defined input tensor, unlike Sequential models where .input might be undefined unless called\n",
        "input_layer = Input(shape=(28, 28, 1), name=\"input_layer\")\n",
        "\n",
        "# -----------------------------\n",
        "# First Convolutional Block\n",
        "# -----------------------------\n",
        "# Conv2D + BatchNorm + MaxPooling + Dropout for regularization and feature extraction\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# -----------------------------\n",
        "# Second Convolutional Block\n",
        "# -----------------------------\n",
        "# More filters to extract complex patterns; layer named for Grad-CAM targeting\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name=\"conv2d_1\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# -----------------------------\n",
        "# Third Convolutional Block\n",
        "# -----------------------------\n",
        "# Deeper representation of image; this conv layer is often used for Grad-CAM\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name=\"conv2d_2\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.25)(x)\n",
        "\n",
        "# -----------------------------\n",
        "# Fully Connected Layers\n",
        "# -----------------------------\n",
        "# Flatten to vector, then use Dense layers for classification\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output_layer = Dense(10, activation='softmax')(x)  # 10 classes for Fashion MNIST\n",
        "\n",
        "# -----------------------------\n",
        "# Build Model using Functional API\n",
        "# -----------------------------\n",
        "# This gives explicit access to model.input and model.output, required for Grad-CAM\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# -----------------------------\n",
        "# Trigger model building\n",
        "# -----------------------------\n",
        "# Functional models need to be 'called' before .output/.input is defined\n",
        "_ = model.predict(np.zeros((1, 28, 28, 1)))  # Dummy call\n",
        "\n",
        "# -----------------------------\n",
        "# Save model for use in Stage 6 (Grad-CAM + Gradio)\n",
        "# -----------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGgzvETCs7BN",
        "outputId": "d045d516-71e5-4c51-a0ff-92e8c2389b7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trainig and fine tubning"
      ],
      "metadata": {
        "id": "plRRY5nctDlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 12. Train the model\n",
        "# ------------------------------------------------------------\n",
        "# Fit the model for 10 epochs with validation\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 13. Evaluate and report accuracy\n",
        "# ------------------------------------------------------------\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"[RESULT] Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"[RESULT] Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 14. Save the trained model\n",
        "# ------------------------------------------------------------\n",
        "model.save(\"models/clothing_recognition_deep_cnn_gradio_modelbuilder.h5\")\n",
        "print(\"[INFO] Trained model saved (Grad-CAM + Gradio ready)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuaVpQzhtNYC",
        "outputId": "8807bcb1-3fde-44b7-9646-f9377fb38f5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 - 16s - 17ms/step - accuracy: 0.7645 - loss: 0.6594 - val_accuracy: 0.8637 - val_loss: 0.3762\n",
            "Epoch 2/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.8496 - loss: 0.4180 - val_accuracy: 0.8850 - val_loss: 0.3139\n",
            "Epoch 3/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.8690 - loss: 0.3599 - val_accuracy: 0.8785 - val_loss: 0.3458\n",
            "Epoch 4/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.8785 - loss: 0.3344 - val_accuracy: 0.8585 - val_loss: 0.4110\n",
            "Epoch 5/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.8862 - loss: 0.3135 - val_accuracy: 0.9072 - val_loss: 0.2576\n",
            "Epoch 6/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.8921 - loss: 0.2991 - val_accuracy: 0.8697 - val_loss: 0.3737\n",
            "Epoch 7/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.8955 - loss: 0.2878 - val_accuracy: 0.8956 - val_loss: 0.2944\n",
            "Epoch 8/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.9009 - loss: 0.2772 - val_accuracy: 0.9085 - val_loss: 0.2551\n",
            "Epoch 9/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.9024 - loss: 0.2689 - val_accuracy: 0.9159 - val_loss: 0.2369\n",
            "Epoch 10/10\n",
            "938/938 - 4s - 4ms/step - accuracy: 0.9071 - loss: 0.2574 - val_accuracy: 0.9158 - val_loss: 0.2424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RESULT] Test Accuracy: 0.9158\n",
            "[RESULT] Test Loss: 0.2424\n",
            "[INFO] Trained model saved (Grad-CAM + Gradio ready)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"models/clothing_recognition_deep_cnn_gradio_modelbuilder.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ugkznUCour7A",
        "outputId": "6903d638-f308-41a2-f81d-bc35722ef512"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4eb6d02f-6b67-4f23-9b69-11913fff32dd\", \"clothing_recognition_deep_cnn_gradio_modelbuilder.h5\", 2982608)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hub-65Bkxun0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}